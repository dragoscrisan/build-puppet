#!/bin/bash

# This is a wrapper script for calling generic worker, such that when the worker
# exits, this script will reboot the machine. Note, in the worker config
# (/etc/generic-worker.config) we set numberOfTasksToRun to 1 so that the worker
# will exit after running a single task. This script is then responsible for
# rebooting the machine.

# If this file exists when the worker starts up, and its content is equal
# to numberOfTasksToRun, the worker won't exit and machine won't reboot.
rm -f tasks-resolved-count.txt

source /usr/local/share/generic-worker/bugzilla-utils.sh

# First run the generic-worker, passing through any arguments handed to this
# wrapper script...
/usr/local/bin/generic-worker "$@" 2>&1 | logger -t generic-worker -s

exitstatus="${PIPESTATUS[0]}"

export TASKCLUSTER_CLIENT_ID="<%= @quarantine_client_id %>"
export TASKCLUSTER_ACCESS_TOKEN="<%= @quarantine_access_token %>"

if [ $exitstatus -eq 69 ]; then
# If generic-worker considers that the host environment is in an invalid/corrupted
# state (for example, it cannot write to disk), it will return the exit code 69.
#
# More information about generic-worker exit codes can be seen here:
# https://docs.taskcluster.net/docs/reference/workers/generic-worker#set-up-your-env
#
# If this happens, we make a call to Taskcluster Queue to quarantine the worker, so
# that no further tasks will be provided to the worker until the quarantine expires.
# This prevents the worker from burning through tasks that it is not able to execute
# properly.
    if [ -f <%= scope.lookupvar('users::builder::home') %>/quarantined ]; then
        echo "Worker is quarantined"
    else
        echo "Quarantine worker"
        # quarantine the worker using github.com/mozilla-platform-ops/quarantine-worker CLI
        /usr/local/bin/quarantine-worker releng-hardware "<%= @worker_type %>" "<%= @worker_group %>" "<%= @hostname %>" 720h5s

        # create a semaphore file
        echo "quarantined worker" > <%= scope.lookupvar('users::builder::home') %>/quarantined

        # Submit a new bug to Bugzilla that reports that the worker has been quarantined, 
        # in order to alert CI Duty to the failure, track status and facilitate resolution.
        create_bug_self_failure
    fi
elif [ $exitstatus -gt 69 -o $exitstatus -lt 69 ]; then
    # If exitstatus is different by 69 (grater than 69 or lower than 69)
    # The worker was removed from the quarantin and run with success a job
    # Remove quarantined file, if file exist
    if [ -f <%= scope.lookupvar('users::builder::home') %>/quarantined ]; then
        /bin/rm -rf <%= scope.lookupvar('users::builder::home') %>/quarantined
    fi
    # Self resolve the bug and remove bug_id file if file exist
    if [ -f <%= scope.lookupvar('users::builder::home') %>/bug_id ]; then
        resolve_bug_self_failure    
        /bin/rm -rf <%= scope.lookupvar('users::builder::home') %>/bug_id
    fi
        # Now reboot the machine immediately (time costs money)
    if [ "<%= @operatingsystem %>" == "Ubuntu" ]; then
        # According to bug 1501936, https://bugzilla.mozilla.org/show_bug.cgi?id=1501936,Linux machines stuck at reboot process.
        # Looking over the internet, I found this bug: https://lists.ubuntu.com/archives/foundations-bugs/2016-April/280724.html
        # They suspet systemd generate this behavior. I reproduced this by genereting a reboot cron job and run it every 10 minutes
        # After around 24 hours the worker stuck at reboot process. I tryed to update systemd to the last version, but without success
        # to fix this, I plan to add --force option to reboot command, to shutdown without contacting the system manager. 
        # According reboot man page:
        # -f, --force - Force immediate halt, power-off, or reboot. When specified once, this results in an immediate but clean shutdown by the system manager. When specified twice, this results in an immediate
        # shutdown without contacting the system manager. See the description of --force in systemctl(1) for more details.
        /usr/bin/sudo /sbin/reboot --force
        # Sleep to prevent this script from terminating naturally, and launchd restarting
        # it. Instead, the shutdown should cause this script to terminate (so it won't
        # really sleep for 2 mins). If shutdown doesn't kick in within 2 mins, it is sane
        # for this script to exit, and allow launchd to fire up the worker again.
        /bin/sleep 120
    else
        /usr/bin/sudo /sbin/reboot
        /bin/sleep 120
    fi
fi
